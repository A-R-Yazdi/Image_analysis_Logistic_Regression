{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Image Analysis\n",
    "\n",
    "A logistic regression classifier (binary) to recognize  images (ankle boot or not).\n",
    "\n",
    "**NOTE:**\n",
    "- for/while loops are avoided when possible to improve efficiency and avoid bottlenecks; Numpy vectorization is implemented instead of loops when possible. \n",
    "\n",
    "**STEPS:**\n",
    "- Processed the data to make it suitable for a binary classification.\n",
    "- Built the general architecture of a learning algorithm, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent) \n",
    "- Gathered all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Overview of the Problem set ##\n",
    "\n",
    "**Problem Statement**: We are given a dataset (\"fashion_mnist\") containing:\n",
    "\n",
    "* a training set of m_train images labeled as:\n",
    "    * Label\tDescription \n",
    "    * 0\t    T-shirt/top\n",
    "    * 1\t    Trouser\n",
    "    * 2\t    Pullover\n",
    "    * 3\t    Dress\n",
    "    * 4\t    Coat\n",
    "    * 5\t    Sandal\n",
    "    * 6\t    Shirt\n",
    "    * 7\t    Sneaker\n",
    "    * 8\t    Bag\n",
    "    * 9\t    Ankle boot\n",
    "\n",
    "* a test set with same labels as the training set\n",
    " \n",
    "\n",
    "Goal: build an image-recognition algorithm that can correctly detect if an image is an ankle boot or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (fmnist)\n",
    "mnist=tf.keras.datasets.fashion_mnist\n",
    "(training_images_orig, training_labels_orig),(test_images_orig, test_labels_orig)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(training_labels_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(test_labels_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = []\n",
    "for i in training_labels_orig:\n",
    "    training_labels.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_labels)):\n",
    "    if training_labels[i] <9:\n",
    "        training_labels[i]=0\n",
    "    else:\n",
    "        training_labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for i in test_labels_orig:\n",
    "    test_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i] <9:\n",
    "        test_labels[i]=0\n",
    "    else:\n",
    "        test_labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24e31a8a6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 20\n",
    "plt.imshow(training_images_orig[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(training_labels_orig[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_orig.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 60000\n",
      "Number of testing examples: m_test = 10000\n",
      "Height/Width of each image: num_px = 28\n",
      "Each image is of size: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m_train = training_images_orig.shape[0]\n",
    "m_test = test_images_orig.shape[0]\n",
    "num_px = training_images_orig.shape[1]\n",
    "\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $*$ num_px $*$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.\n",
    "\n",
    "\n",
    "A trick when flattenning a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_training_labels = np.array(training_labels)\n",
    "arr_training_labels.shape = (len(training_labels),1)\n",
    "fin_training_labels = arr_training_labels.T\n",
    "arr_test_labels = np.array(test_labels)\n",
    "arr_test_labels.shape = (len(test_labels),1)\n",
    "fin_test_labels = arr_test_labels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (784, 60000)\n",
      "fin_train_labels_shape: (1, 60000)\n",
      "test_set_x_flatten shape: (784, 10000)\n",
      "arr_test_labels_shape: (1, 10000)\n",
      "sanity check after reshaping: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  1  0  0 13 73  0  0  1  4  0  0  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "train_set_x_flatten = training_images_orig.reshape(training_images_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_images_orig.reshape(test_images_orig.shape[0],-1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"fin_train_labels_shape: \" + str(fin_training_labels.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"arr_test_labels_shape: \" + str(fin_test_labels.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:110,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_set_x_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_set_x_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "train_set_y = fin_training_labels\n",
    "test_set_y = fin_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity check after normalization: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      " 0.         0.00392157 0.01568627 0.         0.         0.\n",
      " 0.         0.00392157]\n"
     ]
    }
   ],
   "source": [
    "print (\"sanity check after normalization: \" + str(train_set_x[0:110,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - General Architecture of the learning algorithm ##\n",
    "\n",
    "It's time to design a simple algorithm to distinguish ankle boot images from non-ankle boot images.\n",
    "\n",
    "We will build a Logistic Regression, using a Neural Network mindset.\n",
    "\n",
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "The cost is then computed by summing over all training examples:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Key steps**:\n",
    "    - Initialize the parameters of the model\n",
    "    - Learn the parameters for the model by minimizing the cost  \n",
    "    - Use the learned parameters to make predictions (on the test set)\n",
    "    - Analyse the results and conclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Building the parts of our algorithm ## \n",
    "\n",
    "The main steps for building a Neural Network are:\n",
    "1. Define the model structure (such as number of input features) \n",
    "2. Initialize the model's parameters\n",
    "3. Loop:\n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "\n",
    "We often build 1-3 separately and integrate them into one function we call `model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Initializing parameters\n",
    "\n",
    "We implement parameter initialization in the cell below. We have to initialize w as a vector of zeros, look up np.zeros() in the Numpy library's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Forward and Backward propagation\n",
    "\n",
    "Now that your parameters are initialized, we can do the \"forward\" and \"backward\" propagation steps for learning the parameters.\n",
    "\n",
    "We will implement a function `propagate()` that computes the cost function and its gradient.\n",
    "\n",
    "\n",
    "Forward Propagation:\n",
    "- We get X\n",
    "- We compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- We calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Here are the two formulas we will be using: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px , number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-ankle boot, 1 if ankle boot) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "  \n",
    "    A = sigmoid((np.dot(w.T,X)+b))                                    # compute activation\n",
    "    cost = (np.dot(np.log(A),Y.T) + np.dot(np.log(1-A),(1-Y).T))/-m                                # compute cost\n",
    "    \n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "  \n",
    "    dw = (np.dot(X,(A-Y).T))/m\n",
    "    db = np.sum(A-Y)/m\n",
    "   \n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Optimization\n",
    "- We have initialized our parameters.\n",
    "- We are also able to compute a cost function and its gradient.\n",
    "- Now, we want to update the parameters using gradient descent.\n",
    "\n",
    "The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    We basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Now we implement the `predict()` function. There are two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of an ankle boot being present in the picture\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A[0,i] > 0.5:\n",
    "            Y_prediction [0,i] = 1\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Merge all functions into a model ##\n",
    "\n",
    "We will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.\n",
    "\n",
    "We implement the model function and use the following notation:\n",
    "    - Y_prediction_test for predictions on the test set\n",
    "    - Y_prediction_train for predictions on the train set\n",
    "    - w, costs, grads for the outputs of optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 1, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 1, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # initialize parameters with zeros \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs = optimize(w,b,X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples \n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.88166666666666 %\n",
      "test accuracy: 95.88 %\n"
     ]
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test accuracy is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you'll build an even better classifier next week!\n",
    "\n",
    "Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the `index` variable) you can look at predictions on pictures of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'costs': [array(0.69314718), array(0.25828706), array(0.20884488), array(0.18264785), array(0.16650744), array(0.15548312), array(0.14737531), array(0.14107522), array(0.1359707), array(0.13169941), array(0.12803457), array(0.12482761), array(0.12197733), array(0.11941246), array(0.11708131), array(0.11494536), array(0.11297524), array(0.11114807), array(0.10944563), array(0.10785321)], 'Y_prediction_test': array([[1., 0., 0., ..., 0., 0., 0.]]), 'Y_prediction_train': array([[1., 0., 0., ..., 0., 0., 0.]]), 'w': array([[-1.68761600e-06],\n",
      "       [-2.68222810e-06],\n",
      "       [-3.22141351e-05],\n",
      "       [-1.22224554e-04],\n",
      "       [-3.12363229e-04],\n",
      "       [-4.67337514e-04],\n",
      "       [-9.08345322e-04],\n",
      "       [-2.37577171e-03],\n",
      "       [-5.53816518e-03],\n",
      "       [-1.32595726e-02],\n",
      "       [-3.07892474e-02],\n",
      "       [-4.33732569e-02],\n",
      "       [-4.65490106e-02],\n",
      "       [-4.05567118e-02],\n",
      "       [-3.70457860e-02],\n",
      "       [-3.81809825e-02],\n",
      "       [-3.58736291e-02],\n",
      "       [-2.54616632e-02],\n",
      "       [-1.14248810e-02],\n",
      "       [ 2.29319579e-03],\n",
      "       [ 7.57479294e-03],\n",
      "       [ 7.74995079e-03],\n",
      "       [ 6.24889344e-03],\n",
      "       [ 4.29763894e-03],\n",
      "       [ 3.10617359e-03],\n",
      "       [ 2.09610687e-03],\n",
      "       [ 7.06654552e-04],\n",
      "       [ 4.79050008e-05],\n",
      "       [-6.87782604e-06],\n",
      "       [-2.04409052e-05],\n",
      "       [-1.18218354e-04],\n",
      "       [-3.58253405e-04],\n",
      "       [-7.91539635e-04],\n",
      "       [-2.08546027e-03],\n",
      "       [-6.85348006e-03],\n",
      "       [-1.46412330e-02],\n",
      "       [-2.42552248e-02],\n",
      "       [-3.92880381e-02],\n",
      "       [-6.28085795e-02],\n",
      "       [-8.13393443e-02],\n",
      "       [-9.14842607e-02],\n",
      "       [-8.34475649e-02],\n",
      "       [-7.50432216e-02],\n",
      "       [-7.25936790e-02],\n",
      "       [-6.18329058e-02],\n",
      "       [-3.93508893e-02],\n",
      "       [-2.24483907e-02],\n",
      "       [-2.15111196e-03],\n",
      "       [ 9.31464532e-03],\n",
      "       [ 1.53293840e-02],\n",
      "       [ 1.80941498e-02],\n",
      "       [ 1.68658284e-02],\n",
      "       [ 1.48265663e-02],\n",
      "       [ 9.38318193e-03],\n",
      "       [ 3.15652296e-03],\n",
      "       [ 4.54501560e-04],\n",
      "       [-3.20074720e-05],\n",
      "       [-8.47463103e-05],\n",
      "       [-2.81746127e-04],\n",
      "       [-7.05877654e-04],\n",
      "       [-2.08972611e-03],\n",
      "       [-8.22100023e-03],\n",
      "       [-1.81682555e-02],\n",
      "       [-2.50009269e-02],\n",
      "       [-3.38425834e-02],\n",
      "       [-4.98497363e-02],\n",
      "       [-6.96697412e-02],\n",
      "       [-7.43433566e-02],\n",
      "       [-7.29330322e-02],\n",
      "       [-6.65799038e-02],\n",
      "       [-5.74379573e-02],\n",
      "       [-4.49225167e-02],\n",
      "       [-3.46039115e-02],\n",
      "       [-2.88298271e-02],\n",
      "       [-2.10802726e-02],\n",
      "       [-4.48900449e-03],\n",
      "       [ 7.26261997e-03],\n",
      "       [ 1.02683216e-02],\n",
      "       [ 1.24880294e-02],\n",
      "       [ 1.82152818e-02],\n",
      "       [ 2.46886400e-02],\n",
      "       [ 1.84511060e-02],\n",
      "       [ 6.86479575e-03],\n",
      "       [ 1.33278495e-03],\n",
      "       [-5.26476009e-05],\n",
      "       [-2.28722521e-04],\n",
      "       [-6.30105683e-04],\n",
      "       [-1.53224478e-03],\n",
      "       [-5.46275100e-03],\n",
      "       [-1.55012387e-02],\n",
      "       [-2.51995442e-02],\n",
      "       [-3.43179196e-02],\n",
      "       [-4.37174900e-02],\n",
      "       [-5.82424136e-02],\n",
      "       [-7.21373362e-02],\n",
      "       [-7.27470701e-02],\n",
      "       [-6.54322536e-02],\n",
      "       [-5.04885320e-02],\n",
      "       [-3.63619858e-02],\n",
      "       [-2.44798421e-02],\n",
      "       [-1.94740847e-02],\n",
      "       [-1.66942522e-02],\n",
      "       [-1.46272788e-02],\n",
      "       [-5.04753803e-03],\n",
      "       [ 4.01087527e-03],\n",
      "       [ 8.76614001e-03],\n",
      "       [ 1.06563648e-02],\n",
      "       [ 1.52984515e-02],\n",
      "       [ 2.70358827e-02],\n",
      "       [ 2.54927007e-02],\n",
      "       [ 1.18885105e-02],\n",
      "       [ 2.39081318e-03],\n",
      "       [-1.73718131e-04],\n",
      "       [-7.57972360e-04],\n",
      "       [-1.55470568e-03],\n",
      "       [-3.46663367e-03],\n",
      "       [-1.01333711e-02],\n",
      "       [-2.18947328e-02],\n",
      "       [-3.42361181e-02],\n",
      "       [-4.06805409e-02],\n",
      "       [-4.64850371e-02],\n",
      "       [-6.09180852e-02],\n",
      "       [-7.28467026e-02],\n",
      "       [-7.17923239e-02],\n",
      "       [-6.11899696e-02],\n",
      "       [-4.03351541e-02],\n",
      "       [-2.18956436e-02],\n",
      "       [-7.80142290e-03],\n",
      "       [-1.11884274e-03],\n",
      "       [ 1.54033997e-03],\n",
      "       [ 3.55877579e-04],\n",
      "       [ 8.33942468e-03],\n",
      "       [ 1.29812732e-02],\n",
      "       [ 1.12843049e-02],\n",
      "       [ 1.24499223e-02],\n",
      "       [ 1.63889316e-02],\n",
      "       [ 2.78768323e-02],\n",
      "       [ 3.07684395e-02],\n",
      "       [ 1.85178395e-02],\n",
      "       [ 4.24079400e-03],\n",
      "       [-4.57208130e-04],\n",
      "       [-1.83940269e-03],\n",
      "       [-3.40883317e-03],\n",
      "       [-6.67389540e-03],\n",
      "       [-1.58329419e-02],\n",
      "       [-2.96620992e-02],\n",
      "       [-4.03520650e-02],\n",
      "       [-4.48900566e-02],\n",
      "       [-5.12770596e-02],\n",
      "       [-6.57428456e-02],\n",
      "       [-7.53156633e-02],\n",
      "       [-7.28639652e-02],\n",
      "       [-5.87481950e-02],\n",
      "       [-3.60160724e-02],\n",
      "       [-1.22467257e-02],\n",
      "       [ 9.90567769e-03],\n",
      "       [ 2.09149445e-02],\n",
      "       [ 2.28410800e-02],\n",
      "       [ 1.93297935e-02],\n",
      "       [ 2.17554939e-02],\n",
      "       [ 2.77095376e-02],\n",
      "       [ 2.59778342e-02],\n",
      "       [ 2.21237122e-02],\n",
      "       [ 2.58234518e-02],\n",
      "       [ 3.31040781e-02],\n",
      "       [ 3.84205757e-02],\n",
      "       [ 2.74476810e-02],\n",
      "       [ 6.26576420e-03],\n",
      "       [-8.20885083e-04],\n",
      "       [-3.12678640e-03],\n",
      "       [-5.73268565e-03],\n",
      "       [-1.08275936e-02],\n",
      "       [-2.13456078e-02],\n",
      "       [-3.58066408e-02],\n",
      "       [-4.63433658e-02],\n",
      "       [-5.12561940e-02],\n",
      "       [-5.59852070e-02],\n",
      "       [-6.98670700e-02],\n",
      "       [-7.87477796e-02],\n",
      "       [-7.58560733e-02],\n",
      "       [-6.04435151e-02],\n",
      "       [-3.50763241e-02],\n",
      "       [-8.47383428e-03],\n",
      "       [ 2.09287979e-02],\n",
      "       [ 3.83457525e-02],\n",
      "       [ 3.93606930e-02],\n",
      "       [ 3.01766809e-02],\n",
      "       [ 3.30733842e-02],\n",
      "       [ 4.34355311e-02],\n",
      "       [ 4.29307245e-02],\n",
      "       [ 3.91777568e-02],\n",
      "       [ 4.21394737e-02],\n",
      "       [ 4.90353228e-02],\n",
      "       [ 5.39330282e-02],\n",
      "       [ 3.34710743e-02],\n",
      "       [ 5.55785268e-03],\n",
      "       [-1.31193940e-03],\n",
      "       [-4.91147575e-03],\n",
      "       [-8.37907561e-03],\n",
      "       [-1.45730586e-02],\n",
      "       [-2.59087184e-02],\n",
      "       [-4.07691838e-02],\n",
      "       [-5.13818528e-02],\n",
      "       [-5.79616360e-02],\n",
      "       [-6.13817657e-02],\n",
      "       [-7.26612905e-02],\n",
      "       [-8.13535852e-02],\n",
      "       [-7.89928704e-02],\n",
      "       [-6.15374981e-02],\n",
      "       [-3.56143076e-02],\n",
      "       [-5.25769156e-03],\n",
      "       [ 2.76104926e-02],\n",
      "       [ 5.15432983e-02],\n",
      "       [ 4.85183758e-02],\n",
      "       [ 4.19209282e-02],\n",
      "       [ 4.29618955e-02],\n",
      "       [ 5.29253103e-02],\n",
      "       [ 5.85747966e-02],\n",
      "       [ 5.93082240e-02],\n",
      "       [ 6.45479114e-02],\n",
      "       [ 7.47953336e-02],\n",
      "       [ 7.25458166e-02],\n",
      "       [ 2.70494502e-02],\n",
      "       [ 8.87528969e-04],\n",
      "       [-1.83593366e-03],\n",
      "       [-6.39018700e-03],\n",
      "       [-1.03277987e-02],\n",
      "       [-1.75180213e-02],\n",
      "       [-2.92827539e-02],\n",
      "       [-4.41098198e-02],\n",
      "       [-5.46903650e-02],\n",
      "       [-6.38084392e-02],\n",
      "       [-6.64456442e-02],\n",
      "       [-7.48198932e-02],\n",
      "       [-8.30154183e-02],\n",
      "       [-7.96013505e-02],\n",
      "       [-6.24102347e-02],\n",
      "       [-3.29191214e-02],\n",
      "       [ 4.40947397e-03],\n",
      "       [ 3.06167765e-02],\n",
      "       [ 4.41820421e-02],\n",
      "       [ 4.29145800e-02],\n",
      "       [ 4.91087396e-02],\n",
      "       [ 5.51440384e-02],\n",
      "       [ 6.05347369e-02],\n",
      "       [ 6.61058627e-02],\n",
      "       [ 7.29257764e-02],\n",
      "       [ 7.88693440e-02],\n",
      "       [ 8.79571754e-02],\n",
      "       [ 7.73970732e-02],\n",
      "       [ 7.38725019e-03],\n",
      "       [-8.95791492e-03],\n",
      "       [-2.25285950e-03],\n",
      "       [-7.90551208e-03],\n",
      "       [-1.18400848e-02],\n",
      "       [-1.95646591e-02],\n",
      "       [-3.18644588e-02],\n",
      "       [-4.68476549e-02],\n",
      "       [-5.70410453e-02],\n",
      "       [-6.77088937e-02],\n",
      "       [-7.10603796e-02],\n",
      "       [-7.61590524e-02],\n",
      "       [-8.53522400e-02],\n",
      "       [-8.12341401e-02],\n",
      "       [-6.31698403e-02],\n",
      "       [-3.07707748e-02],\n",
      "       [ 9.29252661e-03],\n",
      "       [ 2.01489373e-02],\n",
      "       [ 2.03809793e-02],\n",
      "       [ 2.14074939e-02],\n",
      "       [ 3.93193255e-02],\n",
      "       [ 5.44642743e-02],\n",
      "       [ 5.74971722e-02],\n",
      "       [ 6.49708328e-02],\n",
      "       [ 7.17757189e-02],\n",
      "       [ 7.36346649e-02],\n",
      "       [ 7.62662222e-02],\n",
      "       [ 6.13421273e-02],\n",
      "       [-1.63950722e-02],\n",
      "       [-1.96630355e-02],\n",
      "       [-2.78671556e-03],\n",
      "       [-9.64882190e-03],\n",
      "       [-1.32204771e-02],\n",
      "       [-2.06296959e-02],\n",
      "       [-3.36154039e-02],\n",
      "       [-4.83289699e-02],\n",
      "       [-5.79556593e-02],\n",
      "       [-6.96840125e-02],\n",
      "       [-7.45769083e-02],\n",
      "       [-7.96749636e-02],\n",
      "       [-9.18901443e-02],\n",
      "       [-8.85139422e-02],\n",
      "       [-7.04977677e-02],\n",
      "       [-3.16589299e-02],\n",
      "       [ 4.65059159e-03],\n",
      "       [ 1.10316162e-02],\n",
      "       [ 1.06681244e-02],\n",
      "       [ 1.00088649e-02],\n",
      "       [ 2.47548802e-02],\n",
      "       [ 4.16642484e-02],\n",
      "       [ 4.61595437e-02],\n",
      "       [ 5.67302813e-02],\n",
      "       [ 6.05317861e-02],\n",
      "       [ 5.33914952e-02],\n",
      "       [ 4.84841215e-02],\n",
      "       [ 3.27784316e-02],\n",
      "       [-4.00714316e-02],\n",
      "       [-3.03464321e-02],\n",
      "       [-3.59978158e-03],\n",
      "       [-1.10446987e-02],\n",
      "       [-1.42025910e-02],\n",
      "       [-2.12777873e-02],\n",
      "       [-3.39700090e-02],\n",
      "       [-4.86060924e-02],\n",
      "       [-5.89773071e-02],\n",
      "       [-7.27153048e-02],\n",
      "       [-8.13432634e-02],\n",
      "       [-9.09718936e-02],\n",
      "       [-1.11570085e-01],\n",
      "       [-1.09729250e-01],\n",
      "       [-7.65731635e-02],\n",
      "       [-2.66564519e-02],\n",
      "       [ 1.47804691e-02],\n",
      "       [ 1.49781522e-02],\n",
      "       [ 1.24556876e-02],\n",
      "       [ 9.09732317e-03],\n",
      "       [ 1.38497358e-02],\n",
      "       [ 1.81697253e-02],\n",
      "       [ 2.16048334e-02],\n",
      "       [ 3.23865197e-02],\n",
      "       [ 3.28974556e-02],\n",
      "       [ 2.27035046e-02],\n",
      "       [ 1.93118427e-02],\n",
      "       [ 8.50136502e-03],\n",
      "       [-6.01568926e-02],\n",
      "       [-3.64792778e-02],\n",
      "       [-4.49628680e-03],\n",
      "       [-1.23505766e-02],\n",
      "       [-1.51926910e-02],\n",
      "       [-2.25358958e-02],\n",
      "       [-3.55255415e-02],\n",
      "       [-5.19462804e-02],\n",
      "       [-6.67390970e-02],\n",
      "       [-8.43128560e-02],\n",
      "       [-1.01139938e-01],\n",
      "       [-1.20844998e-01],\n",
      "       [-1.37662417e-01],\n",
      "       [-1.10889613e-01],\n",
      "       [-5.49179211e-02],\n",
      "       [-6.36450444e-03],\n",
      "       [ 2.57443415e-02],\n",
      "       [ 1.50673876e-02],\n",
      "       [ 1.33495434e-02],\n",
      "       [ 1.20303988e-02],\n",
      "       [ 6.67851914e-03],\n",
      "       [-2.21851472e-03],\n",
      "       [-3.84695752e-03],\n",
      "       [ 5.87127031e-03],\n",
      "       [ 5.96972616e-03],\n",
      "       [-4.35481246e-03],\n",
      "       [ 3.04698433e-03],\n",
      "       [ 4.29609327e-04],\n",
      "       [-6.25925397e-02],\n",
      "       [-3.38242932e-02],\n",
      "       [-5.32117679e-03],\n",
      "       [-1.45342998e-02],\n",
      "       [-1.81838950e-02],\n",
      "       [-2.66752972e-02],\n",
      "       [-4.35574743e-02],\n",
      "       [-6.91872611e-02],\n",
      "       [-9.08684940e-02],\n",
      "       [-1.12656972e-01],\n",
      "       [-1.29997514e-01],\n",
      "       [-1.38776536e-01],\n",
      "       [-1.29585838e-01],\n",
      "       [-7.78776629e-02],\n",
      "       [-2.85984753e-02],\n",
      "       [ 7.59404355e-03],\n",
      "       [ 2.49965293e-02],\n",
      "       [ 1.54761993e-02],\n",
      "       [ 1.45209749e-02],\n",
      "       [ 1.45160671e-02],\n",
      "       [ 3.06674990e-03],\n",
      "       [-8.06032825e-03],\n",
      "       [-1.43990956e-02],\n",
      "       [-9.16469085e-03],\n",
      "       [-1.26397563e-02],\n",
      "       [-1.37655238e-02],\n",
      "       [-2.38757428e-03],\n",
      "       [-1.99630629e-04],\n",
      "       [-4.97496604e-02],\n",
      "       [-2.66088856e-02],\n",
      "       [-8.54316222e-03],\n",
      "       [-2.53329097e-02],\n",
      "       [-3.05674521e-02],\n",
      "       [-4.12152389e-02],\n",
      "       [-6.55557494e-02],\n",
      "       [-1.01671043e-01],\n",
      "       [-1.19654549e-01],\n",
      "       [-1.31729637e-01],\n",
      "       [-1.37043317e-01],\n",
      "       [-1.31211317e-01],\n",
      "       [-1.03373903e-01],\n",
      "       [-5.05803720e-02],\n",
      "       [-1.26402903e-02],\n",
      "       [ 1.40664343e-02],\n",
      "       [ 2.69548177e-02],\n",
      "       [ 1.56380199e-02],\n",
      "       [ 1.16114965e-02],\n",
      "       [ 6.16873559e-03],\n",
      "       [-7.93342291e-03],\n",
      "       [-1.38514471e-02],\n",
      "       [-1.50462469e-02],\n",
      "       [-1.46428222e-02],\n",
      "       [-1.81213452e-02],\n",
      "       [-1.73116274e-02],\n",
      "       [-4.98536446e-03],\n",
      "       [-1.49096758e-03],\n",
      "       [-3.37329006e-02],\n",
      "       [-1.85908624e-02],\n",
      "       [-1.78858685e-02],\n",
      "       [-4.49451668e-02],\n",
      "       [-4.43107654e-02],\n",
      "       [-5.30885785e-02],\n",
      "       [-8.03750411e-02],\n",
      "       [-1.16927953e-01],\n",
      "       [-1.26486889e-01],\n",
      "       [-1.31841773e-01],\n",
      "       [-1.33282879e-01],\n",
      "       [-1.17421609e-01],\n",
      "       [-7.86444697e-02],\n",
      "       [-3.35647168e-02],\n",
      "       [-7.02487526e-03],\n",
      "       [ 1.08927410e-02],\n",
      "       [ 2.28525528e-02],\n",
      "       [ 1.15062232e-02],\n",
      "       [ 1.03651234e-03],\n",
      "       [-1.22885054e-02],\n",
      "       [-2.93370539e-02],\n",
      "       [-3.04157803e-02],\n",
      "       [-2.86924553e-02],\n",
      "       [-2.46641141e-02],\n",
      "       [-2.28931381e-02],\n",
      "       [-1.79814277e-02],\n",
      "       [-8.77376208e-03],\n",
      "       [-8.94352498e-03],\n",
      "       [-2.31036653e-02],\n",
      "       [-1.38425625e-02],\n",
      "       [-2.81065427e-02],\n",
      "       [-4.83442198e-02],\n",
      "       [-3.40037969e-02],\n",
      "       [-4.32860123e-02],\n",
      "       [-7.36549606e-02],\n",
      "       [-1.13495565e-01],\n",
      "       [-1.25317049e-01],\n",
      "       [-1.27233060e-01],\n",
      "       [-1.21472821e-01],\n",
      "       [-9.88011995e-02],\n",
      "       [-6.00303642e-02],\n",
      "       [-3.02047716e-02],\n",
      "       [-1.31942850e-02],\n",
      "       [ 3.00153370e-03],\n",
      "       [ 1.26241070e-02],\n",
      "       [-1.94691033e-03],\n",
      "       [-2.11809534e-02],\n",
      "       [-3.49196322e-02],\n",
      "       [-4.55914336e-02],\n",
      "       [-3.81697420e-02],\n",
      "       [-2.19190099e-02],\n",
      "       [-1.35246047e-02],\n",
      "       [-1.60442615e-02],\n",
      "       [-1.48708224e-02],\n",
      "       [-1.15034489e-02],\n",
      "       [-1.51848426e-02],\n",
      "       [-1.28074962e-02],\n",
      "       [-1.07466654e-02],\n",
      "       [-2.57351183e-02],\n",
      "       [-3.20917742e-02],\n",
      "       [-1.45810440e-02],\n",
      "       [-2.76020527e-02],\n",
      "       [-6.28996229e-02],\n",
      "       [-1.01934180e-01],\n",
      "       [-1.12572376e-01],\n",
      "       [-1.13132641e-01],\n",
      "       [-1.03392537e-01],\n",
      "       [-7.91765904e-02],\n",
      "       [-5.14453811e-02],\n",
      "       [-3.17165497e-02],\n",
      "       [-1.74635981e-02],\n",
      "       [ 1.18244237e-03],\n",
      "       [ 6.19855951e-03],\n",
      "       [-1.38932843e-02],\n",
      "       [-3.56019050e-02],\n",
      "       [-4.43410480e-02],\n",
      "       [-3.87701811e-02],\n",
      "       [-1.33123046e-02],\n",
      "       [ 9.08768308e-03],\n",
      "       [ 6.59678076e-03],\n",
      "       [-4.94210630e-03],\n",
      "       [-5.80679675e-03],\n",
      "       [-4.32200848e-03],\n",
      "       [-7.08715060e-03],\n",
      "       [ 2.22538755e-03],\n",
      "       [-1.21772411e-02],\n",
      "       [-9.80436638e-03],\n",
      "       [ 7.58781643e-03],\n",
      "       [ 1.93718379e-02],\n",
      "       [-1.83250684e-03],\n",
      "       [-3.98845620e-02],\n",
      "       [-7.91425558e-02],\n",
      "       [-9.05160270e-02],\n",
      "       [-8.83796658e-02],\n",
      "       [-7.37522793e-02],\n",
      "       [-5.47219293e-02],\n",
      "       [-3.56219075e-02],\n",
      "       [-2.13069598e-02],\n",
      "       [-7.50348870e-03],\n",
      "       [ 8.43994082e-03],\n",
      "       [ 9.26256091e-03],\n",
      "       [-1.21035680e-02],\n",
      "       [-2.84383149e-02],\n",
      "       [-2.58969587e-02],\n",
      "       [-3.11214402e-03],\n",
      "       [ 2.38385005e-02],\n",
      "       [ 3.26164921e-02],\n",
      "       [ 1.48415452e-02],\n",
      "       [ 2.61903823e-03],\n",
      "       [ 8.24087591e-03],\n",
      "       [ 7.84739487e-03],\n",
      "       [ 4.99485942e-03],\n",
      "       [ 1.73013257e-02],\n",
      "       [-1.28625471e-02],\n",
      "       [ 2.77205228e-03],\n",
      "       [ 4.01597770e-02],\n",
      "       [ 5.20919140e-02],\n",
      "       [ 3.24509979e-02],\n",
      "       [-2.81607209e-03],\n",
      "       [-3.69725669e-02],\n",
      "       [-5.09587118e-02],\n",
      "       [-4.80818257e-02],\n",
      "       [-3.70667787e-02],\n",
      "       [-2.31964707e-02],\n",
      "       [-9.86311285e-03],\n",
      "       [-1.48481465e-03],\n",
      "       [ 6.74863782e-03],\n",
      "       [ 1.80636487e-02],\n",
      "       [ 1.58895089e-02],\n",
      "       [-4.33442551e-03],\n",
      "       [-1.24123083e-02],\n",
      "       [ 3.68503822e-03],\n",
      "       [ 2.58923978e-02],\n",
      "       [ 3.90433852e-02],\n",
      "       [ 3.87289340e-02],\n",
      "       [ 2.19707579e-02],\n",
      "       [ 1.55565890e-02],\n",
      "       [ 2.37689645e-02],\n",
      "       [ 2.47094138e-02],\n",
      "       [ 2.21480879e-02],\n",
      "       [ 3.92167027e-02],\n",
      "       [-2.33153685e-03],\n",
      "       [ 7.30093923e-03],\n",
      "       [ 4.59583311e-02],\n",
      "       [ 6.02708440e-02],\n",
      "       [ 5.26021745e-02],\n",
      "       [ 2.52922887e-02],\n",
      "       [-2.04285955e-03],\n",
      "       [-1.28291330e-02],\n",
      "       [-1.21641843e-02],\n",
      "       [-6.18422807e-03],\n",
      "       [ 4.73602404e-03],\n",
      "       [ 1.19471270e-02],\n",
      "       [ 1.82273290e-02],\n",
      "       [ 2.23282184e-02],\n",
      "       [ 3.22876216e-02],\n",
      "       [ 2.98031910e-02],\n",
      "       [ 1.24519275e-02],\n",
      "       [ 1.19210200e-02],\n",
      "       [ 2.63962989e-02],\n",
      "       [ 3.22070015e-02],\n",
      "       [ 3.91254209e-02],\n",
      "       [ 4.77736817e-02],\n",
      "       [ 3.84666846e-02],\n",
      "       [ 4.05733873e-02],\n",
      "       [ 4.85070130e-02],\n",
      "       [ 4.85419907e-02],\n",
      "       [ 4.55852909e-02],\n",
      "       [ 6.23367667e-02],\n",
      "       [ 1.24569362e-02],\n",
      "       [ 7.62038925e-03],\n",
      "       [ 3.49424239e-02],\n",
      "       [ 4.83823946e-02],\n",
      "       [ 4.54074839e-02],\n",
      "       [ 2.71499048e-02],\n",
      "       [ 7.01887129e-03],\n",
      "       [-1.27446942e-03],\n",
      "       [ 4.29180840e-03],\n",
      "       [ 6.89997722e-03],\n",
      "       [ 1.40683565e-02],\n",
      "       [ 1.68378026e-02],\n",
      "       [ 1.92870772e-02],\n",
      "       [ 2.38188425e-02],\n",
      "       [ 2.72775227e-02],\n",
      "       [ 1.84862933e-02],\n",
      "       [ 8.43416900e-03],\n",
      "       [ 7.20833098e-03],\n",
      "       [ 8.56427542e-03],\n",
      "       [ 1.00783862e-03],\n",
      "       [ 1.51229396e-02],\n",
      "       [ 4.58351276e-02],\n",
      "       [ 4.65641194e-02],\n",
      "       [ 5.09208753e-02],\n",
      "       [ 5.93885524e-02],\n",
      "       [ 5.80565114e-02],\n",
      "       [ 5.17803442e-02],\n",
      "       [ 6.25642530e-02],\n",
      "       [ 1.73303341e-02],\n",
      "       [ 8.14880239e-03],\n",
      "       [ 2.62371650e-02],\n",
      "       [ 3.83706770e-02],\n",
      "       [ 3.81058876e-02],\n",
      "       [ 2.49981555e-02],\n",
      "       [ 7.05643162e-03],\n",
      "       [-2.85747735e-03],\n",
      "       [ 2.31748354e-03],\n",
      "       [-1.04034069e-03],\n",
      "       [ 1.92067296e-03],\n",
      "       [ 3.12503354e-03],\n",
      "       [ 1.73170914e-03],\n",
      "       [ 1.58984671e-03],\n",
      "       [ 1.03745000e-03],\n",
      "       [-1.07157342e-03],\n",
      "       [-4.35856184e-03],\n",
      "       [-1.41166327e-02],\n",
      "       [-2.25562841e-02],\n",
      "       [-3.20891552e-02],\n",
      "       [-1.07328287e-02],\n",
      "       [ 2.55072523e-02],\n",
      "       [ 3.29753350e-02],\n",
      "       [ 3.85117542e-02],\n",
      "       [ 4.73383434e-02],\n",
      "       [ 4.52971006e-02],\n",
      "       [ 3.97190782e-02],\n",
      "       [ 4.96350003e-02],\n",
      "       [ 1.54071766e-02],\n",
      "       [ 4.23194829e-03],\n",
      "       [ 1.54854284e-02],\n",
      "       [ 2.58961306e-02],\n",
      "       [ 2.69085955e-02],\n",
      "       [ 1.83905655e-02],\n",
      "       [ 6.48276848e-03],\n",
      "       [-4.16256470e-03],\n",
      "       [-2.80058466e-03],\n",
      "       [-1.08573959e-02],\n",
      "       [-1.38726878e-02],\n",
      "       [-1.79551656e-02],\n",
      "       [-2.17268938e-02],\n",
      "       [-2.09078744e-02],\n",
      "       [-1.63303866e-02],\n",
      "       [-1.04224068e-02],\n",
      "       [-1.91871658e-02],\n",
      "       [-3.44859905e-02],\n",
      "       [-4.97704464e-02],\n",
      "       [-5.04077006e-02],\n",
      "       [-2.57327087e-02],\n",
      "       [ 5.40479803e-03],\n",
      "       [ 1.71672744e-02],\n",
      "       [ 2.34087525e-02],\n",
      "       [ 3.19171993e-02],\n",
      "       [ 2.91570430e-02],\n",
      "       [ 2.38278888e-02],\n",
      "       [ 3.18429479e-02],\n",
      "       [ 1.02244408e-02],\n",
      "       [ 1.51436642e-03],\n",
      "       [ 9.59657253e-03],\n",
      "       [ 1.80817381e-02],\n",
      "       [ 1.72026702e-02],\n",
      "       [ 8.92905715e-03],\n",
      "       [-3.20443566e-05],\n",
      "       [-7.70017317e-03],\n",
      "       [-6.60787576e-03],\n",
      "       [-1.69139794e-02],\n",
      "       [-2.39688055e-02],\n",
      "       [-3.00516448e-02],\n",
      "       [-3.54880418e-02],\n",
      "       [-3.39899703e-02],\n",
      "       [-2.63945945e-02],\n",
      "       [-2.19012541e-02],\n",
      "       [-3.25996815e-02],\n",
      "       [-5.29700992e-02],\n",
      "       [-6.48921551e-02],\n",
      "       [-5.73708024e-02],\n",
      "       [-3.53741878e-02],\n",
      "       [-9.78045520e-03],\n",
      "       [ 7.05428706e-04],\n",
      "       [ 7.52954828e-03],\n",
      "       [ 1.71704450e-02],\n",
      "       [ 1.65106453e-02],\n",
      "       [ 1.16975030e-02],\n",
      "       [ 1.80467936e-02],\n",
      "       [ 6.00712492e-03],\n",
      "       [-1.88715540e-03],\n",
      "       [ 3.36073834e-04],\n",
      "       [ 6.63104173e-03],\n",
      "       [ 8.41940441e-03],\n",
      "       [ 1.66340105e-03],\n",
      "       [-5.60022935e-03],\n",
      "       [-1.11239840e-02],\n",
      "       [-9.25638278e-03],\n",
      "       [-2.00909638e-02],\n",
      "       [-2.81791915e-02],\n",
      "       [-3.71978770e-02],\n",
      "       [-4.51085091e-02],\n",
      "       [-4.34233715e-02],\n",
      "       [-3.46995580e-02],\n",
      "       [-2.95683459e-02],\n",
      "       [-4.36696127e-02],\n",
      "       [-6.43525977e-02],\n",
      "       [-6.84196781e-02],\n",
      "       [-5.88015423e-02],\n",
      "       [-4.17462936e-02],\n",
      "       [-2.13176718e-02],\n",
      "       [-1.10835177e-02],\n",
      "       [-3.38433933e-03],\n",
      "       [ 7.40355307e-03],\n",
      "       [ 9.07443117e-03],\n",
      "       [ 6.87156748e-03],\n",
      "       [ 1.03439074e-02],\n",
      "       [ 3.25973060e-03],\n",
      "       [-1.26338994e-03],\n",
      "       [-3.19205555e-03],\n",
      "       [-4.07470545e-03],\n",
      "       [-6.00519758e-03],\n",
      "       [-1.11212966e-02],\n",
      "       [-1.47191636e-02],\n",
      "       [-1.54015183e-02],\n",
      "       [-9.68816971e-03],\n",
      "       [-1.73433986e-02],\n",
      "       [-2.94208744e-02],\n",
      "       [-4.13177054e-02],\n",
      "       [-5.06730075e-02],\n",
      "       [-4.99141897e-02],\n",
      "       [-4.23940338e-02],\n",
      "       [-4.13895360e-02],\n",
      "       [-5.99922227e-02],\n",
      "       [-7.41241043e-02],\n",
      "       [-7.38098377e-02],\n",
      "       [-6.20957879e-02],\n",
      "       [-4.39386819e-02],\n",
      "       [-2.58001802e-02],\n",
      "       [-1.75540526e-02],\n",
      "       [-1.12922972e-02],\n",
      "       [ 3.82735199e-04],\n",
      "       [ 4.03294520e-03],\n",
      "       [ 4.69198317e-03],\n",
      "       [ 5.58499446e-03],\n",
      "       [ 1.63236867e-03],\n",
      "       [-9.95857117e-05],\n",
      "       [-4.82259835e-04],\n",
      "       [-1.52008416e-03],\n",
      "       [-4.49351634e-03],\n",
      "       [-1.07012044e-02],\n",
      "       [-1.68390228e-02],\n",
      "       [-1.79238998e-02],\n",
      "       [-1.23925620e-02],\n",
      "       [-1.27784293e-02],\n",
      "       [-1.61935239e-02],\n",
      "       [-2.44774915e-02],\n",
      "       [-3.39644815e-02],\n",
      "       [-3.50963952e-02],\n",
      "       [-3.24175143e-02],\n",
      "       [-3.48012052e-02],\n",
      "       [-4.06057809e-02],\n",
      "       [-4.65686125e-02],\n",
      "       [-4.18297450e-02],\n",
      "       [-2.97372976e-02],\n",
      "       [-1.85592411e-02],\n",
      "       [-1.12083702e-02],\n",
      "       [-9.14156922e-03],\n",
      "       [-8.95472961e-03],\n",
      "       [-2.38597008e-03],\n",
      "       [ 9.60238877e-04],\n",
      "       [ 9.52096664e-04],\n",
      "       [ 6.68348781e-04],\n",
      "       [ 1.32031481e-04]]), 'b': -0.3316012370463835, 'learning_rate': 0.005, 'num_iterations': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xuc3HV97/HXe2fv2ewmIZddIBDQAEXEIsvFeileCx4Eq9TCsd6VWpvW6tGWHhU9WHu8trVHbEWL6BEFxWpTjCKegqgtmIAQSBAI4RZzJ9fN3nc/54/fbzc/JjO7m2R/O5ud9/PxmMfM/H7fmfnMb2fnPb/b96uIwMzMDKCm0gWYmdn04VAwM7NRDgUzMxvlUDAzs1EOBTMzG+VQMDOzUQ4Fm5Ek/VDSWypdh9mRxqFgk0rS45JeUek6IuKCiPhapesAkHS7pHdOwes0SLpW0h5JmyW9f5z270vb7U4f15CZt0TSbZK6Jf06+zeV9FZJQ5K6MpfzcnxrNoUcCnbEkVRb6RpGTKdagI8BS4HjgZcCfynp/FINJf0ecAXwcmAJcCLwvzJNvgX8CjgK+BBwk6QFmfn/FREtmcvtk/tWrFIcCjZlJF0o6V5JuyT9p6TTM/OukPSopL2S1kr6/cy8t0r6haS/l7QD+Fg67eeSPitpp6THJF2Qeczor/MJtD1B0h3pa/9E0tWSvlHmPZwnaYOkv5K0GfiqpLmSbpa0LX3+myUdm7b/BPBi4AvpL+ovpNNPkXSrpB2SHpL0hklYxG8GPh4ROyPiQeDLwFvLtH0L8C8RsSYidgIfH2kr6STg+cBHI6InIr4L3A+8fhJqtGnOoWBTQtLzgWuBPyb59fklYHlmk8WjJF+ebSS/WL8hqSPzFOcA64GFwCcy0x4C5gOfBv5FksqUMFbbbwK/TOv6GPCmcd5OOzCP5Bf55ST/R19N7x8H9ABfAIiIDwE/A5alv6iXSZoF3Jq+7kLgMuCLkp5T6sUkfTEN0lKX1WmbucDRwH2Zh94HlHzOdHpx20WSjkrnrY+IvWM81xmStkt6WNJHptkakx0Gh4JNlXcBX4qIuyJiKN3e3wecCxAR34mIjRExHBE3Ao8AZ2cevzEi/k9EDEZETzrtiYj4ckQMAV8DOoBFZV6/ZFtJxwFnAVdGRH9E/BxYPs57GSb5Fd2X/pJ+OiK+GxHd6RfpJ4DfHePxFwKPR8RX0/dzD/Bd4JJSjSPiPRExp8xlZG2rJb3enXnobmB2mRpaSrQlbV88r/i57gBOIwm015OE2gfHeL92BHEo2FQ5Hvgf2V+5wGKSX7dIenNm09Iuki+d+ZnHP1XiOTeP3IiI7vRmS4l2Y7U9GtiRmVbutbK2RUTvyB1JzZK+JOkJSXtIvjTnSCqUefzxwDlFy+KNJGsgh6orvW7NTGsF9pZoO9K+uC1p++J5z3iuiFgfEY+lAX4/cBVlAs2OPA4FmypPAZ8o+pXbHBHfknQ8yfbvZcBRETEHeADIbgrKqzvfTcA8Sc2ZaYvHeUxxLf8DOBk4JyJagZek01Wm/VPAT4uWRUtE/EmpF5P0z0VH+mQvawDS/QKbgOdlHvo8YE2Z97CmRNstEfF0Ou9ESbOL5pd7ruCZfys7gjkULA91khozl1qSL/13SzpHiVmS/lv6xTOL5ItlG4Ckt5GsKeQuIp4AVpHsvK6X9ALgNQf5NLNJ9iPskjQP+GjR/C0kR/eMuBk4SdKbJNWll7Mk/VaZGt9ddKRP9pLdzv914MPpju9TSDbZXVem5q8D75B0aro/4sMjbSPiYeBe4KPp3+/3gdNJNnEh6QJJi9LbpwAfAf5tAsvJjgAOBcvDCpIvyZHLxyJiFcmX1BeAncA60qNdImIt8Dngv0i+QJ8L/GIK630j8ALgaeBvgBtJ9ndM1D8ATcB24E7gR0XzPw9ckh6Z9I/pfodXAZcCG0k2bX0KaODwfJRkh/0TwE+Bz0TEjwAkHZeuWRwHkE7/NHBb2v4JnhlmlwKdJH+rTwKXRMS2dN7LgdWS9pH8rf8V+NvDrN2mCXmQHbNnknQj8OuIKP7FbzbjeU3Bql666eZZkmqUnOx1MfD9StdlVgk+ttgsOernX0nOU9gA/ElE/KqyJZlVhjcfmZnZKG8+MjOzUUfc5qP58+fHkiVLKl2GmdkR5e67794eEQvGa3fEhcKSJUtYtWpVpcswMzuiSHpiIu28+cjMzEY5FMzMbJRDwczMRuUaCpLOTwcQWSfpihLz/z7tGfPetF/2XXnWY2ZmY8ttR3PabfDVwCtJTghaKWl52s8NABHxvkz7PwPOyKseMzMbX55rCmcD69K+1/uBG0i6DyjnMpJxYc3MrELyDIVjeOZgJRvSaQdI+9M/AfiPMvMvl7RK0qpt27aVamJmZpMgz1AoNehGuT41LgVuSodKPPBBEddERGdEdC5YMO65FyWtfHwHn/rRr3G3HmZm5eUZCht45ghWx5L0HV/KpeS86Wj1ht380+2Psqt7IM+XMTM7ouUZCiuBpZJOkFRP8sV/wIDokk4G5pIMsJKbjrZGADbt7h2npZlZ9cotFCJikGTM3VuAB4FvR8QaSVdJuijT9DLghsh5u057Ggqb9/Tk+TJmZke0XPs+iogVJMP1ZaddWXT/Y3nWMMJrCmZm46uaM5oXtDRQI9jiUDAzK6tqQqG2UMPC2Y1eUzAzG0PVhAIk+xU273EomJmVU1Wh0NHmNQUzs7FUVSi0tzWy2aFgZlZWVYVCR1sjXX2D7O31CWxmZqVUVSgsak3PVfDagplZSVUVCh1tTYDPVTAzK6fKQsFrCmZmY6mqUFjY2gB4TcHMrJyqCoWG2gLzW+rd/5GZWRlVFQqQHJbqNQUzs9KqLxRam7xPwcysjKoLhQ53dWFmVlbVhUJ7WyO7ugfo6S858qeZWVWrulAYPSzVawtmZgeoulBoHx1sx0cgmZkVq7pQGDmr2TubzcwOVHWh0N7qYTnNzMqpulBoqi/Q1lTnNQUzsxKqLhTAg+2YmZVTlaGQDMvpHc1mZsWqMhQ6PAKbmVlJVRkK7a1NbO/qp2/QJ7CZmWVVZSiMnMC2dU9fhSsxM5tecg0FSedLekjSOklXlGnzBklrJa2R9M086xmx/wQ2b0IyM8uqzeuJJRWAq4FXAhuAlZKWR8TaTJulwF8DL4yInZIW5lVPVofPajYzKynPNYWzgXURsT4i+oEbgIuL2rwLuDoidgJExNYc6xk1sqawxf0fmZk9Q56hcAzwVOb+hnRa1knASZJ+IelOSeeXeiJJl0taJWnVtm3bDruw2Y11tDTUevORmVmRPENBJaZF0f1aYClwHnAZ8BVJcw54UMQ1EdEZEZ0LFiyYlOLafViqmdkB8gyFDcDizP1jgY0l2vxbRAxExGPAQyQhkTuf1WxmdqA8Q2ElsFTSCZLqgUuB5UVtvg+8FEDSfJLNSetzrGlUe6vXFMzMiuUWChExCCwDbgEeBL4dEWskXSXporTZLcDTktYCtwEfjIin86opq72tka17exkcGp6KlzMzOyLkdkgqQESsAFYUTbsyczuA96eXKdXe1shwwLauvtExFszMql1VntEM2XMVvAnJzGxE1YZCe6tHYDMzK1a1oeA1BTOzA1VtKMxprqOhtobN7urCzGxU1YaCJJ+rYGZWpGpDAXxWs5lZsaoOhY62Jja7Uzwzs1FVHQrtbY1s2dPL8HBxl0xmZtWpqkOho62RgaHg6X39lS7FzGxaqOpQaG9NDkv1fgUzs0RVh8JI9xYegc3MLFHVobCorQHAO5vNzFJVHQrzZzVQWyOfq2BmlqrqUKipEYs8roKZ2aiqDgUYGYHN+xTMzMCh4LOazcwyqj4URvo/Ssb7MTOrblUfCu1tTfQNDrOre6DSpZiZVVzVh4LHVTAz26/qQ6E9DYXNe7yz2cys6kNhZE1h8+6+CldiZlZ5VR8KC1oaqBEegc3MDIcCtYUaFs72CGxmZuBQANJzFdz/kZlZvqEg6XxJD0laJ+mKEvPfKmmbpHvTyzvzrKccj9VsZpbILRQkFYCrgQuAU4HLJJ1aoumNEfHb6eUredUzFvd/ZGaWyHNN4WxgXUSsj4h+4Abg4hxf75B1tDXS1TfI3l6fwGZm1S3PUDgGeCpzf0M6rdjrJa2WdJOkxaWeSNLlklZJWrVt27ZJL3T0XAWvLZhZlcszFFRiWnEHQ/8OLImI04GfAF8r9UQRcU1EdEZE54IFCya5zOwIbA4FM6tueYbCBiD7y/9YYGO2QUQ8HREjZ419GTgzx3rK6vCagpkZkG8orASWSjpBUj1wKbA820BSR+buRcCDOdZT1sLWZFhOrymYWbWrzeuJI2JQ0jLgFqAAXBsRayRdBayKiOXAn0u6CBgEdgBvzauesTTUFpjfUu/+j8ys6uUWCgARsQJYUTTtysztvwb+Os8aJqrd5yqYmfmM5hHtrU3ep2BmVc+hkOpwVxdmZg6FEe1tjezqHqCnf6jSpZiZVYxDITV6WKrXFsysijkUUu2jw3L6CCQzq14OhVR7q09gMzNzKKT2ryk4FMysejkUUs31tbQ11XlNwcyqmkMhw4PtmFm1cyhkJMNyekezmVUvh0JGR5tHYDOz6uZQyGhvbWJ7Vz99gz6Bzcyqk0MhY+QEtq17+sZpaWY2MzkUMnxYqplVO4dChru6MLNq51DIaB8dltNHIJlZdXIoZMxurKOlodabj8ysajkUirT7sFQzq2IOhSLtrT6r2cyql0OhiNcUzKyaTSgUJP3BRKbNBB1tjWzd28vg0HClSzEzm3ITXVP46wlOO+K1tzUyHLCtyyewmVn1qR1rpqQLgFcDx0j6x8ysVmAwz8IqpSNzAltHW1OFqzEzm1pjhgKwEVgFXATcnZm+F3hfXkVVUntrEgTer2Bm1WjMUIiI+4D7JH0zIgYAJM0FFkfEzqkocKp1uKsLM6tiE92ncKukVknzgPuAr0r6u/EeJOl8SQ9JWifpijHaXSIpJHVOsJ7czGmuo6G2xmc1m1lVmmgotEXEHuB1wFcj4kzgFWM9QFIBuBq4ADgVuEzSqSXazQb+HLjrYArPiySPwGZmVWuioVArqQN4A3DzBB9zNrAuItZHRD9wA3BxiXYfBz4NTJtv4fa2Rra4Uzwzq0ITDYWrgFuARyNipaQTgUfGecwxwFOZ+xvSaaMknUGyf2LMoJF0uaRVklZt27ZtgiUfuo62Jq8pmFlVGu/oIwAi4jvAdzL31wOvH+dhKvVUozOlGuDvgbdO4PWvAa4B6OzsjHGaH7aRNYXh4aCmptTbMDObmSZ6RvOxkr4naaukLZK+K+nYcR62AVicuX8sySGuI2YDpwG3S3ocOBdYPh12Nne0NTIwFDy9r7/SpZiZTamJbj76KrAcOJpkE9C/p9PGshJYKukESfXApelzABARuyNifkQsiYglwJ3ARRGx6iDfw6Rb1DoyroI3IZlZdZloKCyIiK9GxGB6uQ5YMNYDImIQWEayL+JB4NsRsUbSVZIuOqyqc7b/XAUflmpm1WVC+xSA7ZL+CPhWev8y4OnxHhQRK4AVRdOuLNP2vAnWkrt2D8tpZlVqomsKbyc5HHUzsAm4BHhbXkVV2vxZDdTWyEcgmVnVmeiawseBt4x0bZGe2fxZkrCYcWpqxKJWj6tgZtVnomsKp2f7OoqIHcAZ+ZQ0PSRnNXufgplVl4mGQk3aER4wuqYw0bWMI5JHYDOzajTRL/bPAf8p6SaSE9DeAHwit6qmgY62Rm5du4WIQPIJbGZWHSZ6RvPXJa0CXkZypvLrImJtrpVVWHtbE32Dw+zqHmDurPpKl2NmNiUmvAkoDYEZHQRZ2XEVHApmVi0muk+h6oycq+DeUs2smjgUyvAIbGZWjRwKZSxoaaBGeAQ2M6sqDoUyags1LJztEdjMrLo4FMawqK3R/R+ZWVVxKIyho9VrCmZWXRwKY/BZzWZWbRwKY+hoa6Srb5C9vQOVLsXMbEo4FMYwOq6C1xbMrEo4FMbQ0dYE+FwFM6seDoUxdHhNwcyqjENhDAtbGwCvKZhZ9XAojKGhtsD8lno27/FZzWZWHRwK4/BhqWZWTRwK42hvbfLmIzOrGg6FcXS4qwszqyIOhXG0tzWyq3uAnv6hSpdiZpY7h8I42lvTw1K9tmBmVSDXUJB0vqSHJK2TdEWJ+e+WdL+keyX9XNKpedZzKPYPtuMjkMxs5sstFCQVgKuBC4BTgctKfOl/MyKeGxG/DXwa+Lu86jlU7urCzKpJnmsKZwPrImJ9RPQDNwAXZxtExJ7M3VlA5FjPIWn3sJxmVkVqc3zuY4CnMvc3AOcUN5L0p8D7gXrgZaWeSNLlwOUAxx133KQXOpbm+lramuq8pmBmVSHPNQWVmHbAmkBEXB0RzwL+CvhwqSeKiGsiojMiOhcsWDDJZY6vo82D7ZhZdcgzFDYAizP3jwU2jtH+BuC1OdZzyNrbGt3VhZlVhTxDYSWwVNIJkuqBS4Hl2QaSlmbu/jfgkRzrOWQd7urCzKpEbvsUImJQ0jLgFqAAXBsRayRdBayKiOXAMkmvAAaAncBb8qrncLS3NrG9q5++wSEaaguVLsfMLDd57mgmIlYAK4qmXZm5/d48X3+yjJyrsHVPH4vnNVe4GjOz/PiM5gkYPVfBZzWb2QznUJiADp+rYGZVwqEwAfvPavYRSGY2szkUJmB2Yx2z6gteUzCzGc+hMEEegc3MqoFDYYI62jwCm5nNfA6FCfKagplVA4fCBHW0NbJ1b69HYDOzGc2hMEHnnngUAbzn+rvpHxyudDlmZrlwKEzQC589n7957Wnc9tA23nvDrxgccjCY2czjUDgIbzzneD5y4an88IHNfOA79zE0PO3GBDIzOyy59n00E73jRSfQ0z/IZ3/8ME31Bf7295+LVGroCDOzI49D4RAse9lSegaGuPq2R2moLfDR15zqYDCzGcGhcIg+8KqT6ekf5tpfPEZzfYG/PP+USpdkZnbYHAqHSBIfufC36BkY4ou3P0pzfYFlL1s6/gPNzKYxh8JhkMQnXnsafQNDfPbHD9NYV+CdLz6x0mWZmR0yh8JhqqkRn77kdHoHh/ibHzxIY12BPzr3+EqXZWZ2SBwKk6C2UMM//OEZ9A7czYe//wBNdQVef+axlS7LzOyg+TyFSVJfW8MX3/h8Xvjso/jgTffxg9WbKl2SmdlBcyhMosa6Al9+cydnHj+X997wK36ydkulSzIzOygOhUnWXF/LtW89i+cc3cp7rr+Hnz2yrdIlmZlNmEMhB7Mb6/ja28/mxAWzeNfXV3HX+qcrXZKZ2YQ4FHIyp7meb7zzHI6Z08Tbr1vJvU/tqnRJZmbjcijkaH5LA9e/81yOamngzf9yF2s27q50SWZmY3Io5Ky9rZHr33kOsxpqeeNX7uIbdz7hbrfNbNrKNRQknS/pIUnrJF1RYv77Ja2VtFrS/5M0I8/6WjyvmW+961xOWjibD3//Ac7//M/4ydotRLjrbTObXnILBUkF4GrgAuBU4DJJpxY1+xXQGRGnAzcBn86rnkpbMn8WN/7xuVzzpjMZHg7e+fVVXPblO7l/gzcpmdn0keeawtnAuohYHxH9wA3AxdkGEXFbRHSnd+8EZvRpwJJ41XPaueV9L+HjFz+HR7Z08Zov/Jz33vArntrRPf4TmJnlLM9QOAZ4KnN/QzqtnHcAPyw1Q9LlklZJWrVt25F/3H9doYY3vWAJt3/wPP70pc/iRw9s5uV/91P+94oH2d0zUOnyzKyK5RkKpUadKbkRXdIfAZ3AZ0rNj4hrIqIzIjoXLFgwiSVW1uzGOj74e6dw2wfO4zWnH801P1vP737mNq79+WP0D3pntJlNvTxDYQOwOHP/WGBjcSNJrwA+BFwUEX051jNtHT2nic+94Xnc/Gcv4rSj27jq5rW88u9/yor7N3lntJlNqTxDYSWwVNIJkuqBS4Hl2QaSzgC+RBIIW3Os5YjwnKPb+L/vOJvr3nYWjbUF3nP9Pbz+n/6Tu5/YUenSzKxK5BYKETEILANuAR4Evh0RayRdJemitNlngBbgO5LulbS8zNNVDUmcd/JCVrz3xXzq9c9lw84eXv9P/8WffONuHtu+r9LlmdkMpyNt80RnZ2esWrWq0mVMme7+Qb58x2N86Y5H6RkY4pwT5nHh6UdzwWntHNXSUOnyzOwIIenuiOgct51D4ciwdW8v19/5JDev3sij2/ZRqBG/86yjuPD0Dn7vOe3Maa6vdIlmNo05FGaoiODXm/dy8+qN/Pt9m3hyRzd1BfHipQu48PQOXnnqImY31lW6TDObZhwKVSAiuP83u7l59SZ+sHoTv9nVQ31tDeedtIALn3c0r/ithTTXe8RVM3MoVJ2I4J4nd3Hz6o2suH8TW/b00VhXw8tPWcSFp3fw0lMW0lhXqHSZZlYhDoUqNjwcrHx8Bzev3sQPH9jE9q5+ZtUXeNlvLeLcE+dx1pJ5PHtBCzU1pc4vNLOZyKFgAAwODXPXYzu4efVGbl27le1dyfmBbU11nHn8XM48fi5nLZnH6ce2eU3CbAZzKNgBIoInd3Sz8vGd3P3EDlY+vpN1W7sAqCuI5x7TRueSeZx5/Fw6j5/rQ17NZhCHgk3Izn393P3ETlY9sZNVj+9g9Ybd9KeDAJ04fxadS+bSefw8OpfM5YT5s5C8ycnsSORQsEPSOzDEA7/ZPbo2seqJnezqTnpundtcxyntrZy0qIWT2mdz8qLZLF00m7YmHwJrNt1NNBR8vKI9Q2Ndgc4l8+hcMg94FsPDwfrtXax8fCf3PrmLh7bs5aa7N7Cvf2j0MR1tjSxdNJuTF7Vw0qLZnNw+m2cvbPHhsGZHIP/X2phqasSzF87m2Qtnc9nZxwHJ0U0bd/fw8Ja9PLS5i0e27OWhLXv52vqnR7v8lmDx3OY0JJKwWLpwNscf1cysBn/szKYr/3faQaupEcfObebYuc287JRFo9OHhoMnnt7Hw1u6ksDYspdHtuzl9oe2Mji8fzPl/JZ6Fs9r5rj0kr29qLWRgg+VNasYh4JNmkKNOHFBCycuaOH809pHp/cPDvPY9n08snUvT+3o4ckd+3hyRzf3PLmTm1dvYigTGPWFGo6d21QyNBbPa3IXHmY5cyhY7uprazi5PdnXUGxgaJhNu3p5ckf36OWp9Prep3YdMDxpS0Mt7W2NtLc2lr5ua2Rec71PzDM7RA4Fq6i6Qg3HHdXMcUc1l5y/u3uAp3buD4tNu3vZsqeXTbt7+fkj29m6t5fhogPo6gs1LGxtoKOtkUWtjaPX7W2NLGhpYP7sBua3NNDaWOtDbM2KOBRsWmtrrqOtuY3TjmkrOX9waJjtXf1s3tPL5t09bN7dy6Y9vWzZnQTH/b/Zza1rt9BXYszr+toa5s+qHw2JJDDqmd/SMHpZkN5va6pzgFhVcCjYEa22UDO62YjFc0q2iQh2dQ+weU8v27v6ksvefrZ39bGtqy8Jld29PPCb3Ty9r/8Z+zhG1BXEUbMamDernrmz6pjbXJ/cbq5nbnMdc2dl7s+qZ15zPU317jbEjjwOBZvxJDF3VvJlPZ7h4WBXz0AaHPtDY+T+zu4Bdnb3s3bjHnZ097O7Z4By53821tWkoZEExpzmOuY019HWlFzmNNXTOnI7M725vuC1EqsYh4JZRk2NmJf+6j9p0YE7xosNDQe7ewbYsa+fnd397NjXz67ufnbsGyi6389vdvWwu2eA3T0DJddGRtQVRFtT3f7AaNofGK1NdcxurKW1sY7ZjXW0NtUyuzE7rdYdG9phcSiYHYZCJkQmKiLo6htkd88Au7oH2JMGxa6R6+7kek/PALt6+tnW1ce6bV3s6h6gq2+w7JrJiPraGlozITEaHg11tDTW0tJQy+z0elZDLS2NtcxOr1sa9l9qCzWHuXTsSORQMJtiktJf93UcO/fgHjs8HOzrH2RP7yB7ewfY2zvInp7kem/vAHt6B9lTYvrmPb3s7R2gq3fwGV2UjKWxroaWhiRYZjUURsOiuT4Nk4YCzfXptHT+rPrM7fT+rLSdT0o8MjgUzI4gNTX7AwWaDuk5hoaD7v5BuvoG6eodZG963ZW9Ti97R6cnaykbd/Wyr3+QfX2D7OsbomdgYgED0FRXYFZDgab6ArPqa4uuCzQ31NJcl16n05rqa9PrArMaammqS2431xdGb9cXarwPZhI5FMyqTCEbLKWP9J2wkYDZ1zdEV9/gaNh09w2xL3O7qy8Jku6BIXr6h9jXN0jPQHK9vauP7v6h9DJI9wTXZLLvp1RYNNWl9+traaqrobk+2d+SzK+hqa5Aw8j99DGNdc98fGNdDY11BRpqqyd4HApmdsieETCTZHg46B1MQ6JviO6BdK0kDY2egZHbQ0W3Bw+Yvqt7INNmkN6B4dHxQg6GRBoSBRpr06CoK9CUhkbjSIDUFmisLyTXo/P2t2moPfD2/mk1NNTuv67U5rZcQ0HS+cDngQLwlYj4ZNH8lwD/AJwOXBoRN+VZj5lNfzU1ork+2XdBy+Q//9Bw0DuwPziyt3sGkvu9A8MHTOvpH6J3cP+8vrRd78AQe3oHkun9Q/QN7p8+OMZRZuOpK+gZIdFQV8P7XnESr3ne0ZO4NA6UWyhIKgBXA68ENgArJS2PiLWZZk8CbwU+kFcdZmZZhRolO8GnoAv3gaHh0ZDpHRiib3Dkeoi+gWF6M9e9A8NJ0AwOl5iXPHZOc/4dQua5VM4G1kXEegBJNwAXA6OhEBGPp/MOfn3OzGyaqyvUUFeoYXZjpSuZuDwPRD4GeCpzf0M6zczMpqk8Q6HUXpJD2sAm6XJJqySt2rZt22GWZWZm5eQZChuAxZn7xwIbD+WJIuKaiOiMiM4FCxZMSnFmZnagPENhJbBU0gmS6oFLgeU5vp6ZmR2m3EIhIgaBZcAtwIPAtyNijaSrJF0EIOksSRuAPwC+JGlNXvWYmdn4cj0mKyJWACuKpl2Zub2SZLOSmZlNA+4G0czMRjkUzMxslGK8ztmnGUnbgCcO8eHzge2TWM5kc32Hx/Udvuleo+s7dMdHxLiHbx5xoXA4JK2KiM5K11GO6zs8ru/wTfcaXV/+vPnIzMxGORTMzGxxaR3PAAAI8klEQVRUtYXCNZUuYByu7/C4vsM33Wt0fTmrqn0KZmY2tmpbUzAzszE4FMzMbNSMDAVJ50t6SNI6SVeUmN8g6cZ0/l2SlkxhbYsl3SbpQUlrJL23RJvzJO2WdG96ubLUc+VY4+OS7k9fe1WJ+ZL0j+nyWy3p+VNY28mZ5XKvpD2S/qKozZQvP0nXStoq6YHMtHmSbpX0SHo9t8xj35K2eUTSW6aots9I+nX69/uepDllHjvmZyHnGj8m6TeZv+Oryzx2zP/3HOu7MVPb45LuLfPYKVmGkyYiZtSFZDzoR4ETgXrgPuDUojbvAf45vX0pcOMU1tcBPD+9PRt4uER95wE3V3AZPg7MH2P+q4EfkoyZcS5wVwX/1ptJTsqp6PIDXgI8H3ggM+3TwBXp7SuAT5V43DxgfXo9N709dwpqexVQm97+VKnaJvJZyLnGjwEfmMBnYMz/97zqK5r/OeDKSi7DybrMxDWF0WFAI6IfGBkGNOti4Gvp7ZuAl0sqNSjQpIuITRFxT3p7L0kPskfaiHQXA1+PxJ3AHEkdFajj5cCjEXGoZ7hPmoi4A9hRNDn7Ofsa8NoSD/094NaI2BERO4FbgfPzri0ifhxJT8YAd1LhjinLLL+JmMj/+2Ebq770u+MNwLcm+3UrYSaGwkSGAR1tk/5j7AaOmpLqMtLNVmcAd5WY/QJJ90n6oaTnTGlhyQh5P5Z0t6TLS8yfLkOtXkr5f8RKLr8RiyJiEyQ/BoCFJdpMh2X5dpI1v1LG+yzkbVm6ievaMpvfpsPyezGwJSIeKTO/0svwoMzEUJjIMKCTNlTooZLUAnwX+IuI2FM0+x6STSLPA/4P8P2prA14YUQ8H7gA+FNJLymaPx2WXz1wEfCdErMrvfwORkWXpaQPAYPA9WWajPdZyNM/Ac8CfhvYRLKJpljFP4vAZYy9llDJZXjQZmIoTGQY0NE2kmqBNg5t1fWQSKojCYTrI+Jfi+dHxJ6I6EpvrwDqJM2fqvoiYmN6vRX4HskqetakDbV6GC4A7omILcUzKr38MraMbFZLr7eWaFOxZZnu1L4QeGOkG7+LTeCzkJuI2BIRQxExDHy5zGtX9LOYfn+8DrixXJtKLsNDMRNDYSLDgC4HRo7yuAT4j3L/FJMt3f74L8CDEfF3Zdq0j+zjkHQ2yd/p6Smqb5ak2SO3SXZIPlDUbDnw5vQopHOB3SObSaZQ2V9nlVx+RbKfs7cA/1aizS3AqyTNTTePvCqdlitJ5wN/BVwUEd1l2kzks5Bnjdn9VL9f5rUrPezvK4BfR8SGUjMrvQwPSaX3dOdxITk65mGSoxI+lE67iuQfAKCRZLPDOuCXwIlTWNuLSFZvVwP3ppdXA+8G3p22WQasITmS4k7gd6awvhPT170vrWFk+WXrE3B1unzvBzqn+O/bTPIl35aZVtHlRxJQm4ABkl+v7yDZT/X/gEfS63lp207gK5nHvj39LK4D3jZFta0j2RY/8hkcORrvaGDFWJ+FKVx+/zf9fK0m+aLvKK4xvX/A//tU1JdOv27kc5dpW5FlOFkXd3NhZmajZuLmIzMzO0QOBTMzG+VQMDOzUQ4FMzMb5VAwM7NRDgXLhaT/TK+XSPrvk/zc/7PUa+VF0mvz6mlVUldOz3uepJsP8zmuk3TJGPOXSXrb4byGTT8OBctFRPxOenMJcFChIKkwTpNnhELmtfLyl8AXD/dJJvC+cpeegTtZrgX+fBKfz6YBh4LlIvML+JPAi9O+5N8nqZD25b8y7ejsj9P25ykZZ+KbJCcsIen7aSdia0Y6EpP0SaApfb7rs6+VnmH9GUkPpP3X/2HmuW+XdJOSMQSuz5zx/ElJa9NaPlvifZwE9EXE9vT+dZL+WdLPJD0s6cJ0+oTfV4nX+ETaed+dkhZlXueSTJuuzPOVey/np9N+TtL1wshjPybpGkk/Br4+Rq2S9IV0efyATAd+pZZTJGdCP56eNW4zxGT+ajAr5QqSPvFHvjwvJ+kW4yxJDcAv0i8rSPqEOS0iHkvvvz0idkhqAlZK+m5EXCFpWUT8donXeh1J52nPA+anj7kjnXcG8BySfnF+AbxQ0lqS7hNOiYhQ6YFmXkjSwV7WEuB3STpru03Ss4E3H8T7ypoF3BkRH5L0aeBdwN+UaJdV6r2sIukf6GUkZysX98VzJvCiiOgZ429wBnAy8FxgEbAWuFbSvDGW0yqSXkJ/OU7NdoTwmoJNtVeR9Jt0L0mX4UcBS9N5vyz64vxzSSNdVSzOtCvnRcC3IulEbQvwU+CszHNviKRztXtJvtj3AL3AVyS9DijVB1AHsK1o2rcjYjiSrpLXA6cc5PvK6gdGtv3fndY1nlLv5RTgsYh4JJJuCr5R9JjlEdGT3i5X60vYv/w2Av+Rth9rOW0l6dbBZgivKdhUE/BnEfGMTt8knQfsK7r/CuAFEdEt6XaSPqvGe+5y+jK3h0hGHRtMN328nKQjtWUkv7Szekh60c0q7hsmmOD7KmEg9vc1M8T+/8lB0h9t6eah+rHeS5m6srI1lKv11aWeY5zl1EiyjGyG8JqC5W0vybCjI24B/kRJ9+FIOklJ75HF2oCdaSCcQjLs54iBkccXuQP4w3Sb+QKSX75lN2soGdOiLZLutf+CZNNTsQeBZxdN+wNJNZKeRdLh2UMH8b4m6nGSTT6QjCRW6v1m/Ro4Ia0Jkl5kyylX6x3Apeny6wBems4fazmdxHTv9dMOitcULG+rgcF0M9B1wOdJNnfck/4C3kbpYSp/BLxb0mqSL907M/OuAVZLuici3piZ/j3gBSQ9UgbwlxGxOQ2VUmYD/yapkeTX8/tKtLkD+JwkZX7RP0SyaWoRSQ+ZvZK+MsH3NVFfTmv7JUkPq2OtbZDWcDnwA0nbgZ8Dp5VpXq7W75GsAdxP0uvoT9P2Yy2nFwL/66DfnU1b7iXVbBySPg/8e0T8RNJ1wM0RcVOFy6o4SWcA74+IN1W6Fps83nxkNr6/JRnDwZ5pPvCRShdhk8trCmZmNsprCmZmNsqhYGZmoxwKZmY2yqFgZmajHApmZjbq/wMqWJfqoWTuogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24e4c037630>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture that was classified.\n",
    "index = 0\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(test_set_y[0,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 23, 28, 39, 68, 83, 107, 108, 122, 123, 132, 158, 163, 165, 178, 181, 185, 186, 203, 208, 232, 234, 242, 250, 268, 291, 297, 307, 316, 346, 348, 349, 372, 375, 377, 392, 401, 414, 428, 441, 448, 456, 470, 477, 479, 481, 493, 495, 514, 518, 524, 537, 549, 556, 576, 583, 593, 601, 606, 609, 623, 630, 644, 680, 683, 687, 692, 704, 706, 709, 730, 756, 772, 776, 780, 784, 794, 810, 820, 839, 847, 848, 855, 876, 883, 884, 892, 917, 936, 940, 962, 970, 980, 981, 995, 1007, 1013, 1016, 1017, 1033, 1045, 1054, 1068, 1084, 1095, 1120, 1133, 1138, 1141, 1143, 1155, 1159, 1187, 1198, 1206, 1209, 1227, 1230, 1272, 1274, 1276, 1291, 1317, 1332, 1341, 1349, 1355, 1410, 1414, 1418, 1422, 1423, 1440, 1445, 1471, 1478, 1488, 1505, 1510, 1522, 1526, 1536, 1537, 1544, 1554, 1594, 1595, 1604, 1607, 1632, 1654, 1657, 1678, 1688, 1695, 1704, 1705, 1709, 1711, 1716, 1718, 1730, 1734, 1735, 1761, 1768, 1781, 1793, 1804, 1805, 1812, 1817, 1838, 1839, 1864, 1875, 1876, 1894, 1899, 1906, 1907, 1916, 1942, 1954, 1960, 1962, 1982, 1993, 2031, 2033, 2034, 2043, 2050, 2051, 2056, 2060, 2066, 2083, 2085, 2087, 2108, 2113, 2132, 2135, 2166, 2167, 2171, 2178, 2180, 2184, 2187, 2201, 2204, 2210, 2214, 2233, 2246, 2250, 2262, 2270, 2285, 2287, 2291, 2314, 2316, 2335, 2339, 2340, 2350, 2365, 2370, 2379, 2399, 2401, 2405, 2432, 2445, 2447, 2448, 2456, 2461, 2472, 2482, 2488, 2494, 2520, 2523, 2525, 2527, 2530, 2537, 2544, 2549, 2550, 2559, 2562, 2577, 2587, 2591, 2625, 2664, 2669, 2702, 2711, 2725, 2740, 2743, 2761, 2768, 2775, 2802, 2808, 2816, 2830, 2846, 2859, 2874, 2903, 2906, 2921, 2934, 2935, 2955, 2969, 2995, 3010, 3015, 3023, 3029, 3043, 3070, 3087, 3097, 3130, 3153, 3160, 3172, 3184, 3186, 3216, 3217, 3227, 3228, 3266, 3299, 3300, 3308, 3310, 3314, 3317, 3368, 3369, 3381, 3383, 3385, 3395, 3399, 3406, 3408, 3434, 3477, 3480, 3495, 3505, 3506, 3511, 3524, 3536, 3576, 3579, 3590, 3605, 3619, 3622, 3641, 3644, 3651, 3656, 3665, 3666, 3674, 3677, 3685, 3692, 3697, 3707, 3711, 3721, 3723, 3728, 3745, 3785, 3786, 3790, 3791, 3798, 3807, 3823, 3832, 3834, 3835, 3838, 3860, 3863, 3888, 3894, 3896, 3907, 3909, 3943, 3968, 3989, 3990, 3999, 4002, 4009, 4014, 4015, 4044, 4045, 4049, 4073, 4077, 4078, 4092, 4120, 4129, 4132, 4133, 4164, 4191, 4215, 4240, 4261, 4270, 4273, 4287, 4296, 4320, 4332, 4334, 4346, 4352, 4369, 4375, 4388, 4390, 4391, 4404, 4406, 4414, 4423, 4438, 4439, 4442, 4450, 4458, 4468, 4474, 4478, 4487, 4497, 4499, 4507, 4511, 4517, 4536, 4538, 4549, 4567, 4568, 4572, 4574, 4584, 4601, 4614, 4615, 4631, 4638, 4653, 4666, 4669, 4676, 4682, 4686, 4698, 4716, 4740, 4743, 4746, 4762, 4800, 4801, 4804, 4821, 4830, 4832, 4848, 4850, 4858, 4865, 4866, 4876, 4885, 4890, 4892, 4906, 4908, 4910, 4913, 4914, 4921, 4957, 4959, 4960, 4975, 4997, 5007, 5009, 5019, 5033, 5044, 5055, 5060, 5069, 5074, 5077, 5089, 5094, 5101, 5102, 5111, 5112, 5116, 5150, 5151, 5162, 5164, 5170, 5174, 5176, 5195, 5219, 5238, 5279, 5293, 5306, 5311, 5314, 5315, 5320, 5321, 5326, 5340, 5348, 5375, 5385, 5386, 5388, 5405, 5406, 5408, 5411, 5416, 5417, 5420, 5427, 5434, 5439, 5446, 5449, 5455, 5476, 5487, 5494, 5512, 5517, 5525, 5528, 5553, 5554, 5560, 5567, 5600, 5626, 5630, 5680, 5684, 5694, 5705, 5722, 5730, 5738, 5743, 5747, 5758, 5765, 5771, 5772, 5787, 5788, 5794, 5807, 5822, 5842, 5850, 5851, 5863, 5864, 5875, 5890, 5891, 5893, 5895, 5938, 5940, 5946, 5948, 5959, 5962, 5975, 5985, 5989, 5995, 6005, 6017, 6018, 6029, 6036, 6040, 6047, 6051, 6052, 6054, 6064, 6069, 6079, 6101, 6106, 6115, 6130, 6136, 6151, 6153, 6163, 6166, 6170, 6176, 6179, 6190, 6192, 6197, 6202, 6203, 6211, 6239, 6253, 6267, 6276, 6283, 6290, 6321, 6324, 6348, 6350, 6359, 6361, 6370, 6383, 6394, 6425, 6442, 6451, 6461, 6471, 6488, 6496, 6537, 6552, 6553, 6555, 6569, 6603, 6611, 6629, 6631, 6635, 6638, 6642, 6644, 6659, 6687, 6704, 6707, 6717, 6729, 6732, 6733, 6738, 6740, 6741, 6754, 6759, 6766, 6769, 6772, 6775, 6793, 6799, 6805, 6823, 6825, 6839, 6858, 6875, 6879, 6883, 6900, 6917, 6932, 6934, 6948, 6965, 6984, 6998, 7005, 7010, 7017, 7021, 7023, 7028, 7044, 7047, 7051, 7062, 7077, 7078, 7090, 7097, 7099, 7102, 7104, 7113, 7125, 7129, 7145, 7148, 7153, 7157, 7162, 7166, 7171, 7186, 7216, 7223, 7246, 7247, 7268, 7274, 7285, 7292, 7297, 7300, 7309, 7316, 7341, 7344, 7354, 7358, 7365, 7366, 7378, 7387, 7399, 7402, 7404, 7418, 7426, 7453, 7457, 7458, 7464, 7469, 7472, 7488, 7494, 7502, 7508, 7521, 7524, 7528, 7530, 7539, 7540, 7542, 7547, 7548, 7550, 7573, 7597, 7598, 7606, 7608, 7609, 7616, 7620, 7644, 7651, 7658, 7661, 7663, 7677, 7703, 7704, 7713, 7716, 7720, 7735, 7745, 7784, 7820, 7835, 7836, 7849, 7860, 7865, 7871, 7877, 7894, 7897, 7902, 7911, 7931, 7936, 7938, 7954, 7983, 8018, 8019, 8020, 8023, 8036, 8037, 8046, 8061, 8068, 8076, 8078, 8079, 8081, 8099, 8109, 8115, 8117, 8124, 8139, 8147, 8166, 8169, 8175, 8192, 8205, 8248, 8253, 8294, 8301, 8304, 8311, 8332, 8342, 8346, 8351, 8367, 8386, 8392, 8395, 8398, 8401, 8407, 8416, 8426, 8427, 8441, 8448, 8460, 8461, 8479, 8487, 8496, 8501, 8504, 8525, 8554, 8557, 8581, 8584, 8590, 8599, 8607, 8640, 8656, 8687, 8688, 8694, 8704, 8711, 8726, 8736, 8739, 8740, 8767, 8780, 8785, 8796, 8816, 8818, 8819, 8833, 8840, 8854, 8856, 8871, 8876, 8889, 8917, 8921, 8922, 8924, 8925, 8932, 8943, 8951, 8952, 8964, 8971, 8976, 8977, 8986, 8998, 9001, 9014, 9018, 9034, 9047, 9052, 9053, 9058, 9066, 9080, 9083, 9104, 9115, 9121, 9135, 9136, 9139, 9150, 9162, 9170, 9175, 9178, 9193, 9201, 9214, 9230, 9246, 9250, 9272, 9281, 9299, 9304, 9312, 9317, 9328, 9332, 9336, 9357, 9358, 9363, 9370, 9372, 9377, 9383, 9392, 9396, 9412, 9418, 9433, 9439, 9447, 9457, 9460, 9472, 9474, 9476, 9506, 9521, 9526, 9528, 9535, 9558, 9559, 9569, 9583, 9614, 9621, 9624, 9630, 9631, 9649, 9655, 9672, 9674, 9677, 9678, 9705, 9726, 9739, 9757, 9759, 9761, 9814, 9835, 9845, 9848, 9878, 9882, 9888, 9911, 9915, 9926, 9937, 9954, 9956, 9964, 9967, 9973, 9978, 9993, 9995]\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(test_set_y.shape[1]):\n",
    "    if test_set_y[0,i]==1:\n",
    "        l.append(i)\n",
    "        \n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_predictions = d['Y_prediction_test']\n",
    "print(test_predictions[0,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
